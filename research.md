# ğŸš¦ Priority Lane

- check out the AI [landscape](https://tracxn.com/d/companies/zhipu/__vs60BhIzHeRwBtLTuoj841aSKyol6J8LYhHaTVGDSrU#about-the-company)

# ğŸ› ï¸ IDE / Coding Agents
*who should you work with? pick your poison*
- [opencode](https://opencode.ai/) - The open source AI coding agent
- [google gemini cli](https://geminicli.com/) - we have free tier and daily consumables
- [claude code](https://claude.com/product/claude-code) - Work with Claude directly in your codebase. Build, debug, and ship from your terminal, IDE, Slack, or the web. Describe what you need, and Claude handles the rest.

- [cursor](https://cursor.com/download) - AI-powered code editor that understands your codebase and helps you code faster through natural language. Just describe what you want to build or change and Cursor will generate the code for you.
- [zed](https://zed.dev/)
- [lovable](lovable.dev) - the basic bitch. generating entire landing pages, basic pages, and emails/html

# ğŸ’Š Steroids <----HERE>

## opencode
- [oh-my-opencode](https://github.com/code-yeongyu/oh-my-opencode) - massive steroid injection; just **do not** setup the **auth providers** because they are failing as of 12-21-2025
- full list of opencode [plugins](https://opencode.ai/docs/ecosystem#plugins)
- oh-my-opencode agent model [alternatives](./oh-my-opencode-models.md)

## cursor
- [cursor-commands](https://github.com/hamzafer/cursor-commands) - some prebuilt commands for your cursor
- [awesome-cursor](https://github.com/hao-ji-xing/awesome-cursor) - A curated collection of tools and resources for Cursor.
- [cursor.directory](https://cursor.directory/)

### Vibe Coding
- [vibe-tools](https://github.com/eastlondoner/vibe-tools)

### Limits
- [https://support.claude.com/en/articles/11145838-using-claude-code-with-your-pro-or-max-plan#h_50f6dec29d](https://support.claude.com/en/articles/11145838-using-claude-code-with-your-pro-or-max-plan#h_50f6dec29d)


# ğŸ“° Articles

## Model Comparison / Best Usage

- Github Copilot [model-comparison](https://docs.github.com/en/copilot/reference/ai-models/model-comparison)
- Github Copilot [PREMIUM USAGE](https://docs.github.com/en/copilot/concepts/billing/copilot-requests) References

## Context is King!

- [Effective context engineering for AI agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
- [https://research.trychroma.com/context-rot](https://research.trychroma.com/context-rot)
  - [reddit](https://www.reddit.com/r/LocalLLaMA/comments/1m4fs2t/context_rot_how_increasing_input_tokens_impacts/)
    - [https://arxiv.org/abs/2402.14848](https://arxiv.org/abs/2402.14848) 
    - [https://arxiv.org/abs/2502.05167](https://arxiv.org/abs/2502.05167)
    - [https://arxiv.org/abs/2404.02060](https://arxiv.org/abs/2404.02060)
- [context-rot-the-emerging-challenge](https://www.understandingai.org/p/context-rot-the-emerging-challenge)
- [context benchmarked](https://www.letta.com/blog/context-bench)
- the million context [scam](https://www.reddit.com/r/LocalLLaMA/comments/1mq19x6/1_million_context_is_the_scam_the_ai_start/)
- zhipu [prompt-engineering](https://docs.bigmodel.cn/cn/coding-plan/best-practice/prompt-engineering)

## ğŸ“š Benchmarks / Leaderboards

- [SuperClue AI](https://www.superclueai.com/generalpage) ğŸ‡¨ğŸ‡³ - Most traffic
- [FlagEval](https://flageval.baai.ac.cn/#/leaderboard) ğŸ‡¨ğŸ‡³ - most in depth of them all
- [artificial analysis](https://artificialanalysis.ai/models/kimi-k2) ğŸ‡¨ğŸ‡³ - all ai model general benchmarks here
- [Nejumi Dashboard](https://nejumi.ai/) ğŸ‡¯ğŸ‡µ - Nejumi Leaderboard evaluates response consistency by testing JMMLU with multiple patterns (standard method, symbolic choices, selecting non-correct answers)
- [Nejumi Dashboard - Legacy](https://wandb.ai/wandb-japan/llm-leaderboard) ğŸ‡¯ğŸ‡µ - See how leading models stack up across text, image, vision, and beyond. This page gives you a snapshot of each Arena, you can explore deeper insights in their dedicated tabs.
- open [ko-llm](https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard) ğŸ‡°ğŸ‡·
- [llm-arena](https://lmarena.ai/leaderboard) ğŸŒğŸŒğŸŒ
- [livebench](https://livebench.ai/#/?sort=Coding+Average) by AI21 Labs ğŸ‡®ğŸ‡±
- [Berkeley Function-Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html) ğŸ‡ºğŸ‡¸
- Russian [SuperGlue](https://russiansuperglue.com/leaderboard/2) ğŸ‡·ğŸ‡º - rigorous adaptation of the original Western GLUE/SuperGLUE benchmarks but completely re-engineered for the Russian language's complex morphology (cases, genders)
- [SEAL SCALE](https://scale.com/leaderboard?category=agentic) by Scale AI ğŸ‡ºğŸ‡¸
- [SEA LLMS](https://huggingface.co/spaces/SeaLLMs/LLM_Leaderboard_for_SEA) ğŸ‡®ğŸ‡©ğŸ‡µğŸ‡­ğŸ‡»ğŸ‡³ğŸ‡¸ğŸ‡¬ğŸ‡²ğŸ‡¾ - Southeast asian LLMs
- [Taiwan](https://huggingface.co/datasets/syntaxsynth/tmmluplus) ğŸ‡¹ğŸ‡¼ - Taiwan Leaderboard

# ğŸ—‚ï¸ MCPs

- [gemini MCP list](https://geminicli.com/extensions/#_top)
- [gemini MCP installations](https://geminicli.com/docs/tools/mcp-server/)
- [awesome-mcp-servers](https://github.com/wong2/awesome-mcp-servers) - Curated Model Context Protocol (MCP) servers.
- [sentry mcp](https://docs.sentry.io/product/sentry-mcp/)
- [context7](https://context7.com) - band aid solution for mcps

## others
- [aider](https://aider.chat/)
- [construct](https://github.com/furisto/construct) - API-first multi-agent coding assistant with CodeAct tool calling and first-class terminal support.
- [Warp Docs](https://docs.warp.dev/) - Official Warp documentation (Agentic Development Environment, Warp AI, agents, Warp Drive).

# ğŸ›¡ï¸ Security

- [strix](https://github.com/usestrix/strix) - Open-source AI agents for penetration testing.

# Checker

- [SandboxFusion](https://bytedance.github.io/SandboxFusion/docs/docs/get-started)

# ğŸ’¬ Discussion

- [Excalidraw](https://excalidraw.com/) - Collaborative diagramming tool.
- Why I switched from [Claude Code to Warp](https://levelup.gitconnected.com/why-i-switched-from-claude-code-to-warp-920ab7fcef8b)

# ğŸ’¸ Pricing & Cost Analysis

- [Pricing Models and Cost Analysis](./pricing.md) - This document outlines the pricing models for LLMs and cloud services (e.g., AWS), detailing cost factors and optimization strategies for managing expenses within the AI Factory.
- Private [Doc](https://docs.google.com/spreadsheets/d/1bkSfaSsEbTcl1Fv0uqGk2RMJW9jJMt-NOapV7cP5u44/edit?gid=0#gid=0)



## 1. Reviews: GitHub Copilot Pro vs. Pro+

User sentiment draws a notable line between these two tiers: Copilot Pro shines for "daily driving" (routine coding), while Pro+ attracts users who often tackle "architectural" or complex software work.

### GitHub Copilot Pro ($10/month)

**Positive Reviews**
- **"The 10x Typist"**: Loved for rapidly writing boilerplate (React components, unit tests, regex). Many say "it feels like it reads your mind" for standard code.
- **IDE Native**: Deep integration with VS Code/JetBrains means no context switchingâ€”just code and go.
- **Student/Entry Value**: Frequently recommended as the best value for students or junior developers needing syntax help.

**Negative Reviews**
- **"Context Amnesia"**: Increasing complaints (late 2024/25) that Copilot "forgets" recent code or ignores referenced (@workspace) files.
- **Quality Degradation**: Veteran users feel it's "dumber" than at launch, sometimes hallucinating libraries or suggesting deprecated syntax.
- **Chat Latency**: Standard chat support can be slow, especially during US peak hours.

### GitHub Copilot Pro+ ($39/month)

**Positive Reviews**
- **Model Switching**: The standout feature. Users enjoy seamless switches to Claude 3.7/OpenAI o3 for heavier logic, all within Copilot UIâ€”no need for multiple paid tools.
- **Priority Lane**: Noticeably faster, more reliable responses (fewer "network error" timeouts) at busy times.
- **Agent Mode**: Excels at handling multi-step refactors, e.g., renaming variables project-wide, far beyond what's possible with Pro.

**Negative Reviews**
- **Price Shock**: Many view $39 as steep, since you could access similar models cheaper via direct API if you're willing to set up your own tooling.
- **Overkill for Maintenance**: If you're just maintaining legacy code, Pro+'s higher-end models can be too verbose and slower than needed.

---

## 2. Comparison: Copilot vs. Claude Code vs. Gemini Code Assist

| Feature           | GitHub Copilot (Pro/Pro+)               | Claude Code (Anthropic)             | Gemini Code Assist                       |
|-------------------|-----------------------------------------|-------------------------------------|------------------------------------------|
| **Primary "Vibe"**| The "Fast Autocomplete". Feels like an extension of your fingers. | The "Senior Engineer". Autonomous and plans before acting. | The "Google Expert". Giant context, cloud-native.   |
| **Best For**      | Speed, boilerplate, standard web/app dev, working inside the IDE. | Large refactors, strict logic, complex architecture, CLI power users.   | Projects with massive codebases (1M+ tokens); Google Cloud devs. |
| **Token Efficiency** | Medium. Can waste tokens on repetition/context loss. | Low (default); reads everything to ensure correctness (expensive but accurate). | Highâ€”efficient with huge promptsâ€”cheaper per unit context. |
| **Weakness**      | Struggles with logic over 50+ files ("big picture"). | Slowerâ€”"thinks" before acting. CLI may not fit all. | Suggestions can be less "idiomatic" than Copilot.   |

---

## 3. Token-Saving Criteria for Development (OpenCode / Agent Tools)

If you're using OpenCode (CLI agent) or any "Bring Your Own Key" (BYOK) LLM toolsâ€”where you pay for every tokenâ€”apply this "Low-Overhead Context" approach:

### A. The "Read-Only" Rule
- **Donâ€™t** allow the agent to scan your whole repo for every queryâ€”input tokens are ~90% of your cost.
- **Do** manually select just the interface/header files relevant for the task.
  - **Example**: Fixing a bug in `auth.ts`? Provide only `auth.ts` and `types.ts`â€”not `database.ts` or `server.ts` unless truly needed.

### B. Prefer TOON (Token-Oriented Object Notation) over JSON
- **Why**: Benchmarks (late 2025) show JSON wastes massive tokens on brackets `{}`, quotes `""`, and repeated keys.
- **What to do**: If your tool supports it, request data in YAML or "TOON" format. This cuts token use for structured data by ~30â€“50%.

### C. The "Lint-First" Workflow
- **Anti-pattern**: Donâ€™t ask the AI agent to â€œfix bugsâ€ before youâ€™ve linted. It will waste tokens discovering syntax errors your linter catches instantly.
- **Fix**: Run your local linter/formatter (ESLint, Prettier, Ruff, etc.) before sending code to the AI; only submit code that compiles.
- **Protocol**: Ask AI for logic fixes, not syntax fixes.

### D. Model Routing ("Tiered" Approach)
- **Strategy**: Configure your agent to use different models for each task.
  - **Search/Planning**: Use Haiku 3.5 or Flash 2.0 (cheap, fast, good for finding code location).
  - **Coding/Writing**: Use Sonnet 3.5 or GPT-4o (reliable, general purpose).
  - **Complex Debugging**: Only jump to Opus or o1/o3 when you need more horsepower.

---

## 4. Summary Recommendations

- **For a subscription (flat fee):**
  - *Get GitHub Copilot Pro+* if you need Claude/o1 models in VS Code and want everything in one place.
  - *Get Claude Code (Pro)* if you prefer working in the terminal, need robust "do it for me" agents (such as full-directory refactors).

- **For OpenCode/BYOKâ€“style tools (pay per token):**
  - *Strict context control*: Never dump your full repo (`.`) into the prompt context.
  - *Diff-only outputs*: Ask the model to "Return only the diff in unified format, no explanation." This cuts output token cost by up to 80%.